{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Treinamento de Modelo de Previsão de Preço de Diamantes\n",
    "\n",
    "Este notebook treina dois modelos Keras (Redes Neurais) para prever o preço de diamantes com base em suas características (4Cs e dimensões). Também implementa uma lógica de Ensemble (Voting) para combinar as previsões."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instalar dependências necessárias\n",
    "!pip install tensorflow pandas seaborn scikit-learn joblib numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import joblib\n",
    "import os\n",
    "\n",
    "print(f\"TensorFlow Version: {tf.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Carregamento e Pré-processamento de Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carregar dataset\n",
    "# Usamos o seaborn como fonte fácil, mas você pode fazer upload do CSV do Kaggle\n",
    "try:\n",
    "    df = pd.read_csv('diamonds.csv')\n",
    "    print(\"Carregado de diamonds.csv\")\n",
    "except:\n",
    "    print(\"Arquivo local não encontrado, carregando do Seaborn...\")\n",
    "    df = sns.load_dataset('diamonds')\n",
    "\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pré-processamento\n",
    "y = df['price']\n",
    "X = df.drop('price', axis=1)\n",
    "\n",
    "categorical_cols = ['cut', 'color', 'clarity']\n",
    "numerical_cols = ['carat', 'depth', 'table', 'x', 'y', 'z']\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', StandardScaler(), numerical_cols),\n",
    "        ('cat', OneHotEncoder(handle_unknown='ignore', sparse_output=False), categorical_cols)\n",
    "    ]\n",
    ")\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "X_train_processed = preprocessor.fit_transform(X_train)\n",
    "X_test_processed = preprocessor.transform(X_test)\n",
    "\n",
    "input_shape = X_train_processed.shape[1]\n",
    "print(f\"Input Shape: {input_shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Definição e Treinamento dos Modelos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model_1(input_shape):\n",
    "    model = keras.Sequential([\n",
    "        layers.Dense(64, activation='relu', input_shape=[input_shape]),\n",
    "        layers.Dense(32, activation='relu'),\n",
    "        layers.Dense(1)\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='mae', metrics=['mae'])\n",
    "    return model\n",
    "\n",
    "def create_model_2(input_shape):\n",
    "    model = keras.Sequential([\n",
    "        layers.Dense(128, activation='relu', input_shape=[input_shape]),\n",
    "        layers.Dropout(0.2),\n",
    "        layers.Dense(64, activation='relu'),\n",
    "        layers.Dense(32, activation='relu'),\n",
    "        layers.Dense(1)\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='mae', metrics=['mae'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Treinando Modelo 1...\")\n",
    "model1 = create_model_1(input_shape)\n",
    "history1 = model1.fit(X_train_processed, y_train, validation_split=0.2, batch_size=32, epochs=50, verbose=0)\n",
    "\n",
    "print(\"Treinando Modelo 2...\")\n",
    "model2 = create_model_2(input_shape)\n",
    "history2 = model2.fit(X_train_processed, y_train, validation_split=0.2, batch_size=32, epochs=50, verbose=0)\n",
    "\n",
    "print(\"Treinamento concluído.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Avaliação e Voting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss1, mae1 = model1.evaluate(X_test_processed, y_test, verbose=0)\n",
    "loss2, mae2 = model2.evaluate(X_test_processed, y_test, verbose=0)\n",
    "\n",
    "print(f\"Modelo 1 MAE: {mae1:.2f}\")\n",
    "print(f\"Modelo 2 MAE: {mae2:.2f}\")\n",
    "\n",
    "# Voting (Média)\n",
    "pred1 = model1.predict(X_test_processed).flatten()\n",
    "pred2 = model2.predict(X_test_processed).flatten()\n",
    "pred_voting = (pred1 + pred2) / 2\n",
    "\n",
    "mae_voting = np.mean(np.abs(y_test - pred_voting))\n",
    "print(f\"Voting Ensemble MAE: {mae_voting:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Salvar Modelos\n",
    "Salva os modelos no formato `.keras` e o preprocessor com `joblib`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1.save(\"model1.keras\")\n",
    "model2.save(\"model2.keras\")\n",
    "joblib.dump(preprocessor, \"preprocessor.joblib\")\n",
    "print(\"Arquivos salvos: model1.keras, model2.keras, preprocessor.joblib\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exemplo de como carregar e usar\n",
    "loaded_model = keras.models.load_model(\"model1.keras\")\n",
    "# loaded_preprocessor = joblib.load(\"preprocessor.joblib\")\n",
    "# prediction = loaded_model.predict(loaded_preprocessor.transform(new_data))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
