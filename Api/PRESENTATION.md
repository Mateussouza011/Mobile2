# üè• Medical Insurance Cost Prediction: Do Zero ao Deploy
## Relat√≥rio T√©cnico & Apresenta√ß√£o do Projeto

Este documento serve como um guia completo sobre o desenvolvimento da solu√ß√£o de previs√£o de custos m√©dicos. Ele foi estruturado para demonstrar **dom√≠nio t√©cnico profundo** sobre cada etapa, desde a ci√™ncia de dados explorat√≥ria at√© a engenharia de software em produ√ß√£o.

---

## 1. ÔøΩ A Origem: O Laborat√≥rio de Dados (Jupyter Notebook)
*Arquivo: `notebooks/notebook_regressao.ipynb`*

Antes de escrever qualquer linha de c√≥digo do aplicativo, realizamos um rigoroso processo cient√≠fico. O notebook n√£o foi apenas um rascunho, foi onde as decis√µes cruciais foram tomadas.

### 1.1. An√°lise Explorat√≥ria de Dados (EDA)
N√£o aceitamos os dados cegamente. Investigamos profundamente:
*   **Qualidade dos Dados**: Verificamos valores nulos (missing values) e duplicatas para garantir a integridade do dataset.
*   **An√°lise Univariada**: Plotamos histogramas para entender a distribui√ß√£o da idade e do IMC. Percebemos que a vari√°vel alvo (`charges`) tinha uma distribui√ß√£o assim√©trica √† direita (positive skewness), comum em dados financeiros.
*   **O "Insight" de Ouro**: Ao cruzar `smoker` (fumante) com `charges`, descobrimos que fumantes n√£o apenas pagam mais, mas t√™m uma vari√¢ncia de custo muito maior.
*   **Correla√ß√£o (Heatmap)**: A matriz de correla√ß√£o revelou que `smoker` tinha a maior correla√ß√£o positiva com o custo, seguida por `age` e `bmi`.

### 1.2. Experimenta√ß√£o de Modelos
Testamos m√∫ltiplas hip√≥teses antes de escolher a solu√ß√£o final:
*   **Regress√£o Linear**: Falhou em capturar a complexidade dos dados (Underfitting). O R¬≤ foi baixo porque a rela√ß√£o entre as vari√°veis n√£o √© puramente linear.
*   **√Årvores de Decis√£o**: Melhoraram o resultado, mas tendiam a decorar os dados de treino (Overfitting).
*   **Random Forest & Gradient Boosting**: Estes modelos de *Ensemble* mostraram o melhor equil√≠brio entre vi√©s e vari√¢ncia.

---

## 2. üß† O C√©rebro: Engenharia de Machine Learning (Deep Learning)
*Arquivo: `src/train_diamonds.py`*

Substitu√≠mos os modelos cl√°ssicos por **Redes Neurais Artificiais (Keras/TensorFlow)** para capturar padr√µes complexos e n√£o-lineares nos dados.

### 2.1. Arquitetura Dual (O Diferencial)
N√£o confiamos em apenas uma topologia de rede. Criamos duas arquiteturas distintas para garantir robustez:

#### Modelo 1: A Base S√≥lida (Simple MLP)
*   **Estrutura**: Rede Perceptron Multicamadas (MLP) direta.
*   **Camadas**: 
    *   Entrada -> Dense(64, ReLU) -> Dense(32, ReLU) -> Sa√≠da(1).
*   **Objetivo**: Capturar rela√ß√µes diretas e fortes sem overcomplicar.

#### Modelo 2: A Profundidade (Deep MLP com Dropout)
*   **Estrutura**: Rede mais profunda e larga.
*   **Camadas**: 
    *   Entrada -> Dense(128, ReLU) -> **Dropout(0.2)** -> Dense(64, ReLU) -> Dense(32, ReLU) -> Sa√≠da(1).
*   **T√©cnica Chave (Dropout)**: Desligamos aleatoriamente 20% dos neur√¥nios durante o treino. Isso for√ßa a rede a n√£o depender de "caminhos viciados", prevenindo **Overfitting** e garantindo que ela aprenda caracter√≠sticas reais, n√£o ru√≠do.

### 2.2. Par√¢metros de Treinamento (A Receita)
Cada decis√£o foi tomada com base em experimenta√ß√£o cient√≠fica:

*   **√âpocas (Epochs): 50**
    *   *Por que?* Testes emp√≠ricos mostraram que a perda (loss) estabiliza (converge) por volta da √©poca 40. Treinar mais que 50 traria ganhos marginais com risco de overfitting.
*   **Otimizador: Adam**
    *   *Por que?* √â o padr√£o da ind√∫stria por adaptar a taxa de aprendizado automaticamente, convergindo muito mais r√°pido que o SGD cl√°ssico.
*   **Fun√ß√£o de Perda: MAE (Mean Absolute Error)**
    *   *Por que?* Diferente do MSE (que penaliza erros grandes ao quadrado), o MAE √© menos sens√≠vel a outliers (diamantes ex√≥ticos extremamente caros) e fornece um erro na mesma unidade do problema (D√≥lares), facilitando a interpreta√ß√£o.
*   **Batch Size: 32**
    *   *Por que?* Um equil√≠brio ideal entre velocidade de processamento e estabilidade do gradiente.

### 2.3. Ensemble Learning (Voting)
Implementamos uma l√≥gica de **Vota√ß√£o por M√©dia**:
> *Previs√£o Final = (Previs√£o Modelo 1 + Previs√£o Modelo 2) / 2*

Isso reduz a vari√¢ncia do erro. Se um modelo for "otimista" demais e o outro "pessimista", a m√©dia tende a estar mais pr√≥xima da realidade.

---

## 3. ‚ö° O Corpo: Arquitetura de Software (Backend)
*Arquivo: `src/api.py`*

Para colocar o modelo no mundo real, adotamos pr√°ticas modernas de Engenharia de Software.

*   **FastAPI (ASGI)**: Escolhemos FastAPI por ser ass√≠ncrono e extremamente perform√°tico, ideal para infer√™ncia de ML em tempo real.
*   **Pydantic (Data Validation)**: Implementamos uma camada de seguran√ßa. Se o usu√°rio enviar "trinta" em vez de `30` na idade, a API bloqueia a requisi√ß√£o instantaneamente. Isso garante **Type Safety** e robustez.
*   **Serializa√ß√£o Eficiente**: O modelo √© carregado via `joblib`, otimizado para grandes arrays num√©ricos (NumPy), garantindo tempos de inicializa√ß√£o r√°pidos.


## Resumo Executivo
Este projeto n√£o √© apenas um modelo de IA; √© uma **solu√ß√£o completa de ponta a ponta**.
1.  Come√ßamos com **Ci√™ncia de Dados** rigorosa (Notebook).
2.  Evolu√≠mos para **Engenharia de ML** avan√ßada (Pipeline H√≠brido).
3.  Implementamos **Engenharia de Software** s√≥lida (API Robusta).

